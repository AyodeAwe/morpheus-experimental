{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO1UZU2O8wCv"
      },
      "source": [
        "\n",
        "# URL phishing detection model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqSTBFBk9Du9"
      },
      "source": [
        "### Table of Contents\n",
        "* Introduction\n",
        "* Dataset\n",
        "* Data Preprocessing\n",
        "* Model Training\n",
        "* Conclusions\n",
        "* References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kihTnzx1-Ac0"
      },
      "source": [
        "# Introduction\n",
        "URL phishing is the fraudulent practice of luring individuals to an imposter website where they will download malicious software or reveal confidential information. \n",
        "#### Example of a URL Phishing Attack\n",
        "One of the most common examples of a URL phishing attack is where a fraudster mimics a known company, sending a bogus email with a message saying “Your account has been disabled. Click here to restore it.” \n",
        "\n",
        "Alarmed users then click the link and unwittingly install malware onto their computer. URL phishing goes even further: the cybercriminal creates a bogus website that is linked within the email. When users click it, they go to a site that looks legitimate, but is actually a trap."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvqDLSTB-h_8"
      },
      "source": [
        "# Dataset\n",
        "We gather 500K malicious url from popular and open source dataset and also couple of hundreds URLs from windows os memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJckzNLC9z_P"
      },
      "source": [
        "# Imports installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE_EPnO394NF"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "! pip install tensorflow\n",
        "! pip install tldextract\n",
        "! pip install swifter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt6Gx60A-fZl"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV_Vj7oG8pPj"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.parse import urlparse\n",
        "import tldextract\n",
        "import os\n",
        "import random\n",
        "import re,unicodedata\n",
        "from string import punctuation\n",
        "\n",
        "import swifter\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwtisThM_FPH"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djKe6oiC8pPl"
      },
      "outputs": [],
      "source": [
        "# Stractural feature of the url\n",
        "ADDITIONAL_FEATURES = ['domain_in_alexa','domain_len','domain_numbers','domain_isalnum','subdomain_len','subdomain_numbers_count',\n",
        "            'subdomain_parts_count','tld_len','tld_parts_count','queries_amount','fragments_amount',\n",
        "            'path_len','path_slash_counts','path_double_slash_counts','brand_in_subdomain','brand_in_path','path_max_len']\n",
        "# Max words in each url\n",
        "MAX_LEN= 500\n",
        "# Number of words in nlp model\n",
        "NLP_TOKENS = 2000\n",
        "# Number of epochs\n",
        "NUM_EPOCHS = 150 \n",
        "# Size eof batch\n",
        "BATCH_SIZE = 2000\n",
        "# Size of embedding layer\n",
        "EMBEDDING_DIM = 16\n",
        "# Classes weight\n",
        "CLASS_WEIGHTS = {0: 4000, 1:1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYQ5bvIi_Mdc"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWuPxRUf8pPn"
      },
      "outputs": [],
      "source": [
        "# Clean url text\n",
        "def clean(text):   \n",
        "    # strip '\n",
        "    text = text.strip(\"'\")\n",
        "    # convert to lower letters\n",
        "    text = text.lower()  \n",
        "    # remove punctuation marks\n",
        "    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n",
        "    # remove extra spaces\n",
        "    text = re.sub(' +', ' ', text)   \n",
        "    # strip spaces\n",
        "    text = text.strip(\" \")  \n",
        "    return text\n",
        "# Clean url with remove short and long words\n",
        "def clean_nlp(text):\n",
        "    text = clean(text)\n",
        "    text = ' '.join([x for x in text.split(' ') if x.isnumeric()==False and len(x)>1 and len(x)<21])\n",
        "    return text\n",
        "# Strip ' ' and '\\n'\n",
        "def strip_se(url):\n",
        "    return url.strip(\"'\").strip('\\n')\n",
        "# Add 'http://' for url if needed\n",
        "def add_http(url):\n",
        "    if url.startswith('http'):\n",
        "        return url\n",
        "    return 'http://'+url\n",
        "# Get domain\n",
        "def get_domain(url):\n",
        "    domain = tldextract.extract(url).domain\n",
        "    if domain:\n",
        "        return domain\n",
        "    return ''\n",
        "# Get subdomain\n",
        "def get_subdomain(url):\n",
        "    subdomain = tldextract.extract(url).subdomain\n",
        "    if subdomain:\n",
        "        return subdomain\n",
        "    return ''\n",
        "# Get tld\n",
        "def get_tld(url):\n",
        "    tld = tldextract.extract(url).suffix\n",
        "    if tld:\n",
        "        return tld\n",
        "    return ''\n",
        "# Parse the url\n",
        "def get_url_parsed(url):\n",
        "    url_parsed = urlparse(url)\n",
        "    return url_parsed\n",
        "# Get url's path\n",
        "def get_path(url):\n",
        "    url_parsed = urlparse(url)\n",
        "    return url_parsed.path\n",
        "# Get url len\n",
        "def get_len(s):\n",
        "    return len(s)\n",
        "# Get count of nubers in input\n",
        "def get_count_numbers(s):\n",
        "    return sum(c.isdigit() for c in s)\n",
        "# Check if input is alpha-numeric\n",
        "def get_not_alphanumeric(s):\n",
        "    if s.isalnum() == True:\n",
        "        return 1\n",
        "    return 0\n",
        "# Get count of dots\n",
        "def get_count_parts(s):\n",
        "    return len(s.split('.'))\n",
        "# Get count of queries\n",
        "def get_count_queries(s):\n",
        "    url_parsed_query = urlparse(s).query\n",
        "    if url_parsed_query == '':\n",
        "        return 0\n",
        "    return len(url_parsed_query.split('&'))\n",
        "# Get count of fragments\n",
        "def get_count_fragments(s):\n",
        "    url_parsed_fragment = urlparse(s).fragment\n",
        "    if url_parsed_fragment == '':\n",
        "        return 0\n",
        "    return 1\n",
        "# Get count of slash\n",
        "def get_count_slash(s):\n",
        "    return s.count('/')\n",
        "# Get count of double slash\n",
        "def get_double_slash(s):\n",
        "    return s.count('//')\n",
        "# Get count of upper letters\n",
        "def get_count_upper(s):\n",
        "    return sum(1 for c in s if c.isupper())\n",
        "# Check if brand in subdomain\n",
        "def get_brand_in_subdomain(s):\n",
        "    for brand in ['whatsapp','netflix','dropbox','wetransfer','rakuten','itau','outlook','ebay','facebook','hsbc','linkedin','instagram','google','paypal','dhl','alibaba','bankofamerica','apple','microsoft','skype','amazon','yahoo','wellsfargo','americanexpress']:\n",
        "        if brand in s:\n",
        "            return 1\n",
        "    return 0\n",
        "# Check if brand in path\n",
        "def get_brand_in_path(s):\n",
        "    for brand in ['whatsapp','netflix','dropbox','wetransfer','rakuten','itau','outlook','ebay','facebook','hsbc','linkedin','instagram','google','paypal','dhl','alibaba','bankofamerica','apple','microsoft','skype','amazon','yahoo','wellsfargo','americanexpress']:\n",
        "        if brand in s:\n",
        "            return 1\n",
        "    return 0\n",
        "# Check if domain is in Alexa rank\n",
        "def get_domain_alexa(s):\n",
        "    if s in alexa_rank_1k_domain_unique:\n",
        "        return 2\n",
        "    elif s in alexa_rank_100k_domain_unique:\n",
        "        return 1\n",
        "    return 0\n",
        "# Get max of parts length\n",
        "def get_max_len_path(path_clean):\n",
        "    if path_clean == '':\n",
        "        return 0\n",
        "    path_split = [len(f) for f in path_clean.split()]\n",
        "    return np.max(path_split,0)\n",
        "# Check path empty\n",
        "def check_path_empty(path):\n",
        "    if path.strip(\"/\") == \"\":\n",
        "        return 1\n",
        "    return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ebx6RxC8pPq"
      },
      "outputs": [],
      "source": [
        "# Calculating the features\n",
        "def create_features(df):\n",
        "    df['domain_in_alexa'] = df['domain'].swifter.apply(get_domain_alexa)\n",
        "    df['domain_len'] = df['domain'].swifter.apply(get_len)\n",
        "    df['domain_numbers'] = df['domain'].swifter.apply(get_count_numbers)\n",
        "    df['domain_isalnum'] = df['domain'].swifter.apply(get_not_alphanumeric)\n",
        "    df['subdomain_len'] = df['subdomain'].swifter.apply(get_len)\n",
        "    df['subdomain_numbers_count'] = df['subdomain'].swifter.apply(get_count_numbers)\n",
        "    df['subdomain_parts_count'] = df['subdomain'].swifter.apply(get_count_parts)\n",
        "    df['tld_len'] = df['tld'].swifter.apply(get_len)\n",
        "    df['tld_parts_count'] = df['tld'].swifter.apply(get_count_parts)\n",
        "    df['url_len'] = df['url'].swifter.apply(get_len)\n",
        "    df['queries_amount'] = df['url'].swifter.apply(get_count_queries)\n",
        "    df['fragments_amount'] = df['url'].swifter.apply(get_count_fragments)\n",
        "    df['path_len'] = df['path'].swifter.apply(get_len)\n",
        "    df['path_slash_counts'] = df['path'].swifter.apply(get_count_slash)\n",
        "    df['path_double_slash_counts'] = df['path'].swifter.apply(get_double_slash)\n",
        "    df['upper_amount'] = df['url'].swifter.apply(get_count_upper)\n",
        "    df['brand_in_subdomain'] = df['subdomain'].swifter.apply(get_brand_in_subdomain)\n",
        "    df['brand_in_path'] = df['path'].swifter.apply(get_brand_in_path)  \n",
        "    url_df['path_clean'] = url_df['path'].swifter.apply(lambda x: clean(x))\n",
        "    url_df['path_max_len'] = url_df['path_clean'].swifter.apply(get_max_len_path)\n",
        "    url_df['path_empty'] = df['path'].swifter.apply(check_path_empty)  \n",
        "    return df\n",
        "# Processing the url - domain, subdomain, tld, path and get URL's features\n",
        "def processing(df):\n",
        "    # strip url\n",
        "    df['url'] = df['url'].apply(strip_se)\n",
        "    # add http\n",
        "    df['url'] = df['url'].apply(add_http)\n",
        "    #df['url'].apply(get_url_parsed)\n",
        "    # get domain\n",
        "    df['domain'] = df['url'].apply(get_domain)\n",
        "    # get sub domain\n",
        "    df['subdomain'] = df['url'].apply(get_subdomain)\n",
        "    # get tld\n",
        "    df['tld'] = df['url'].apply(get_tld)\n",
        "    # get path\n",
        "    df['path'] = df['url'].apply(get_path)\n",
        "    # Create features\n",
        "    df = create_features(df)\n",
        "    return df\n",
        "# Data processing\n",
        "def data_preprocessing(df):\n",
        "    df = processing(df)  \n",
        "    df['url_clean'] = df['url_clean'].apply(lambda x: clean_nlp(x))\n",
        "    df['url_clean'] = df['url_clean'].apply(lambda x: clean_nlp(x))\n",
        "    X = df[['url','url_clean']+ADDITIONAL_FEATURES+['label']]\n",
        "    # Split the data for malicious and benign\n",
        "    X_mal = X[X['label'] == 1]\n",
        "    X_ben = X[X['label'] == 0]\n",
        "    Y_mal = X_mal.pop('label')\n",
        "    Y_ben = X_ben.pop('label')\n",
        "    # Split the data to train and test\n",
        "    X_mal_train, X_mal_test, Y_mal_train, Y_mal_test = train_test_split(X_mal, Y_mal, train_size=0.25)\n",
        "    X_ben_train, X_ben_test, Y_ben_train, Y_ben_test = train_test_split(X_ben, Y_ben, train_size=0.8)\n",
        "    X_train = X_mal_train.append(X_ben_train)\n",
        "    Y_train = Y_mal_train.append(Y_ben_train)\n",
        "    X_test = X_mal_test.append(X_ben_test)\n",
        "    Y_test = Y_mal_test.append(Y_ben_test)\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "# Stractural features processing\n",
        "def stractural_processing(X_train, X_test):\n",
        "    # Train and test features dataframe\n",
        "    X_train_features = X_train[ADDITIONAL_FEATURES]\n",
        "    X_test_features = X_test[ADDITIONAL_FEATURES]\n",
        "    \n",
        "    max_dict = {}\n",
        "    min_dict = {}\n",
        "    \n",
        "    # Normalize the features\n",
        "    for feature in X_train_features.columns:\n",
        "        max_dict[feature] = X_train_features[feature].max()\n",
        "        min_dict[feature] = X_train_features[feature].min()\n",
        "        X_test_features[feature] = (X_test_features[feature] - X_train_features[feature].min()) / (X_train_features[feature].max() - X_train_features[feature].min())    \n",
        "        X_train_features[feature] = (X_train_features[feature] - X_train_features[feature].min()) / (X_train_features[feature].max() - X_train_features[feature].min())    \n",
        "    \n",
        "    df_max_min = pd.DataFrame(columns = max_dict.keys())\n",
        "    df_max_min = df_max_min.append(min_dict, ignore_index=True)\n",
        "    df_max_min = df_max_min.append(max_dict, ignore_index=True)\n",
        "    return X_train_features, X_test_features, df_max_min\n",
        "# NLP data processing    \n",
        "def nlp_processing(X_train, X_test):\n",
        "    \n",
        "    # Train and test nlp dataframe\n",
        "    X_train_nlp = X_train['url_clean']\n",
        "    X_test_nlp = X_test['url_clean']\n",
        "    # Convert the words to tokens\n",
        "    tokenizer = Tokenizer(num_words=NLP_TOKENS)\n",
        "    \n",
        "    tokenizer.fit_on_texts(X_train_nlp)\n",
        "    vocab_length = tokenizer.num_words + 1\n",
        "    \n",
        "    X_train_nlp = tokenizer.texts_to_sequences(X_train_nlp)\n",
        "    X_test_nlp = tokenizer.texts_to_sequences(X_test_nlp)\n",
        "    \n",
        "    X_train_nlp = pad_sequences(X_train_nlp, maxlen=MAX_LEN, padding='post')\n",
        "    X_test_nlp = pad_sequences(X_test_nlp, maxlen=MAX_LEN, padding='post')\n",
        "    tokenizer_df = pd.DataFrame()\n",
        "    tokenizer_df['keys'] = list(tokenizer.word_index.keys())[0:NLP_TOKENS]\n",
        "    tokenizer_df['values'] = list(tokenizer.word_index.values())[0:NLP_TOKENS]\n",
        "    return X_train_nlp, X_test_nlp, tokenizer_df, vocab_length\n",
        "# Model training\n",
        "def train_model(X_train_nlp, X_train_features, Y_train):\n",
        "    \n",
        "    # Defining the model\n",
        "    inputA = tf.keras.layers.Input(shape=(X_train_nlp.shape[1],))\n",
        "    inputB = tf.keras.layers.Input(shape=(X_train_features.shape[1],))\n",
        "    # First input will process the url text\n",
        "    x = tf.keras.layers.Embedding(vocab_length, EMBEDDING_DIM, input_length=MAX_LEN)(inputA)\n",
        "    x = tf.keras.layers.LSTM(256, return_sequences=True)(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.Model(inputs=inputA, outputs=x)\n",
        "    # Second input will process the structural of the url\n",
        "    y = tf.keras.layers.Dense(6, activation=\"relu\")(inputB)\n",
        "    y = tf.keras.Model(inputs=inputB, outputs=y)\n",
        "    # Combine the processing of the text and structural of the url\n",
        "    combined = tf.keras.layers.concatenate([x.output, y.output])\n",
        "    # Apply softmax\n",
        "    z = tf.keras.layers.Dense(1, activation='sigmoid')(combined)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[x.input, y.input], outputs=z)\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
        "    \n",
        "    # Train the model\n",
        "    history = model.fit(x=[X_train_nlp, X_train_features], y=Y_train, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,workers=8 ,use_multiprocessing=True,\n",
        "                        class_weight=CLASS_WEIGHTS)\n",
        "\n",
        "    return model\n",
        "# Model evaluation\n",
        "def model_eval(model, X_test_nlp, X_test_features, Y_test):\n",
        "    # Inferencing the test data\n",
        "    Y_pred = model.predict([X_test_nlp, np.array(X_test_features)])\n",
        "    X_test['pred'] = Y_pred\n",
        "    X_test['label'] = Y_test\n",
        "    # Plotting precision-recall curve \n",
        "    recall = []\n",
        "    precision = []\n",
        "    ratio_malicious_benign = 0.05\n",
        "    flag_pass = False\n",
        "    thr_final = 0\n",
        "    for thr in np.arange(0, 1, 0.01):\n",
        "        FPs = len(X_test[(X_test['pred']>thr) & (X_test['label']==0)])\n",
        "        len_ben = len(X_test[X_test['label']==0])\n",
        "        len_mal = len_ben*ratio_malicious_benign\n",
        "        recall_step = len(X_test[(X_test['pred']>thr) & (X_test['label']==1)])/len(X_test[X_test['label']==1])\n",
        "        recall.append(recall_step)\n",
        "        TPs = len_mal*recall_step\n",
        "        precision.append(TPs/(TPs+FPs))\n",
        "        if TPs/(TPs+FPs) > 0.9 and flag_pass == False:\n",
        "            print('Presicion: {}'.format(TPs/(TPs+FPs)))\n",
        "            print('Recall: {}'.format(recall_step))\n",
        "            print('Threshhold: {}'.format(thr))\n",
        "            thr_final = thr\n",
        "            flag_pass = True\n",
        "    plt.plot(recall, precision, marker='.')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('URLS model')\n",
        "# Model saving\n",
        "def save_model(df_max_min, tokenizer_df, model):\n",
        "    df_max_min.to_csv('max_min_urls.csv',index=False)\n",
        "    tokenizer_df.to_csv('tokenizer_urls.csv',index=False)\n",
        "    model.save('url_model_keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PSLuT4p8pPt"
      },
      "outputs": [],
      "source": [
        "# Read Alexa rank domain dataframe\n",
        "alexa_rank = pd.read_csv('../datasets/alexa-top-500k.csv',header=None)\n",
        "alexa_rank.columns = ['index','url']\n",
        "alexa_rank_domain = alexa_rank['url'].apply(get_domain)\n",
        "alexa_rank_1k = alexa_rank_domain.iloc[0:1000]\n",
        "alexa_rank_100k = alexa_rank_domain.iloc[1000:100000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrcH9k238pPu"
      },
      "outputs": [],
      "source": [
        "alexa_rank_1k_domain_unique = pd.unique(alexa_rank_1k)\n",
        "alexa_rank_100k_domain_unique = pd.unique(alexa_rank_100k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssvTl6AH__Hd"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWP4a_q_8pPw"
      },
      "outputs": [],
      "source": [
        "url_df = pd.read_csv(\"../datasets/url_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzxusDVWAB-S"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "660e993c29624753891307fb3d5bfcd5",
            "6863894e2be84acf8a9f655bce9245e8",
            "9dee7195d95449a8a642720d87637a9b",
            "044c77517a91471c90d3fc314d1271f5",
            "8539bf3a60154b84a3b24d40505e9970",
            "323b8201e87b406c842b20f297d30747",
            "3ea568401bbf41e1ba59dda500d348ca",
            "0aec2d30d2cc42f597028c3d0100731c",
            "a583b3fa16094622ad29af4801549cfb",
            "193b05768dd64354b999a9f9acc897d7",
            "a0af45ac62bd4225b3f799cde403aa57",
            "d5402b6e32c14d83b990d3ad6b08f2f1",
            "473783fcae9246ab854aec5e1729e783",
            "344d2fa658f74155b8fbf6f79c843970",
            "393b8b59337a453fae668f420b8d7ba7",
            "836c22afd7a44764ae955e26d5463657",
            "b7dd0cde88bc4524bbcd736157efa3f0",
            "cc7498b84cc6417396e7008ace875981",
            "89b4eba41bc64405b8ba4898fd42a841",
            "2ca1e808f6be4bfcbda563ae995696c2",
            "f9311606e81d4a6db335fd7c0a8b2cab"
          ]
        },
        "id": "PlFg9CzE8pP0",
        "outputId": "132d695f-7185-4cde-9094-1ffabfea79fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data for url model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "660e993c29624753891307fb3d5bfcd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6863894e2be84acf8a9f655bce9245e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dee7195d95449a8a642720d87637a9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "044c77517a91471c90d3fc314d1271f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8539bf3a60154b84a3b24d40505e9970",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "323b8201e87b406c842b20f297d30747",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ea568401bbf41e1ba59dda500d348ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0aec2d30d2cc42f597028c3d0100731c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a583b3fa16094622ad29af4801549cfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "193b05768dd64354b999a9f9acc897d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0af45ac62bd4225b3f799cde403aa57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5402b6e32c14d83b990d3ad6b08f2f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "473783fcae9246ab854aec5e1729e783",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "344d2fa658f74155b8fbf6f79c843970",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "393b8b59337a453fae668f420b8d7ba7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "836c22afd7a44764ae955e26d5463657",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7dd0cde88bc4524bbcd736157efa3f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc7498b84cc6417396e7008ace875981",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89b4eba41bc64405b8ba4898fd42a841",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ca1e808f6be4bfcbda563ae995696c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9311606e81d4a6db335fd7c0a8b2cab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=523802.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Processing data for url model...\")\n",
        "X_train, Y_train, X_test, Y_test = data_preprocessing(url_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkOU3s7jAFy0"
      },
      "source": [
        "# Processing the stractural features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znUXzL-k8pP2",
        "outputId": "560c7fb2-979b-4d92-b2d7-7d92499212bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating stractural URL features...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-1e191699079d>:73: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_test_features[feature] = (X_test_features[feature] - X_train_features[feature].min()) / (X_train_features[feature].max() - X_train_features[feature].min())\n",
            "<ipython-input-5-1e191699079d>:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train_features[feature] = (X_train_features[feature] - X_train_features[feature].min()) / (X_train_features[feature].max() - X_train_features[feature].min())\n"
          ]
        }
      ],
      "source": [
        "print(\"Calculating stractural URL features...\")\n",
        "X_train_features, X_test_features, df_max_min = stractural_processing(X_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q-MYDn3AOLN"
      },
      "source": [
        "# NLP processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNzTzTJ-8pP4",
        "outputId": "7cd6bced-be06-4cc4-eda0-cb346329d996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating NLP URL features...\n"
          ]
        }
      ],
      "source": [
        "print(\"Calculating NLP URL features...\")\n",
        "X_train_nlp, X_test_nlp, tokenizer_df, vocab_length = nlp_processing(X_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ypvf11jAQ2j"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_U0AXPI48pP5",
        "outputId": "1fdeda92-d448-42f6-b795-0d3a0408bef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train URL model...\n",
            "Epoch 1/150\n",
            "103/103 [==============================] - 818s 8s/step - loss: 78.0393 - accuracy: 0.5230\n",
            "Epoch 2/150\n",
            "103/103 [==============================] - 783s 8s/step - loss: 4.6850 - accuracy: 0.6010\n",
            "Epoch 3/150\n",
            "103/103 [==============================] - 763s 7s/step - loss: 3.5247 - accuracy: 0.5398\n",
            "Epoch 4/150\n",
            "103/103 [==============================] - 751s 7s/step - loss: 3.9873 - accuracy: 0.5228\n",
            "Epoch 5/150\n",
            "103/103 [==============================] - 752s 7s/step - loss: 4.3824 - accuracy: 0.5228\n",
            "Epoch 6/150\n",
            "103/103 [==============================] - 779s 8s/step - loss: 4.4531 - accuracy: 0.5228\n",
            "Epoch 7/150\n",
            "103/103 [==============================] - 762s 7s/step - loss: 4.4717 - accuracy: 0.5228\n",
            "Epoch 8/150\n",
            "103/103 [==============================] - 740s 7s/step - loss: 4.4687 - accuracy: 0.5228\n",
            "Epoch 9/150\n",
            "103/103 [==============================] - 729s 7s/step - loss: 4.4649 - accuracy: 0.5228\n",
            "Epoch 10/150\n",
            "103/103 [==============================] - 735s 7s/step - loss: 4.4613 - accuracy: 0.5228\n",
            "Epoch 11/150\n",
            "103/103 [==============================] - 715s 7s/step - loss: 4.4548 - accuracy: 0.5228\n",
            "Epoch 12/150\n",
            "103/103 [==============================] - 720s 7s/step - loss: 4.4452 - accuracy: 0.5228\n",
            "Epoch 13/150\n",
            "103/103 [==============================] - 718s 7s/step - loss: 4.4315 - accuracy: 0.5228\n",
            "Epoch 14/150\n",
            "103/103 [==============================] - 718s 7s/step - loss: 4.4134 - accuracy: 0.5228\n",
            "Epoch 15/150\n",
            "103/103 [==============================] - 724s 7s/step - loss: 4.3898 - accuracy: 0.5228\n",
            "Epoch 16/150\n",
            "103/103 [==============================] - 719s 7s/step - loss: 4.3610 - accuracy: 0.5228\n",
            "Epoch 17/150\n",
            "103/103 [==============================] - 723s 7s/step - loss: 4.3286 - accuracy: 0.5228\n",
            "Epoch 18/150\n",
            "103/103 [==============================] - 717s 7s/step - loss: 4.2931 - accuracy: 0.5228\n",
            "Epoch 19/150\n",
            "103/103 [==============================] - 720s 7s/step - loss: 4.2564 - accuracy: 0.5229\n",
            "Epoch 20/150\n",
            "103/103 [==============================] - 721s 7s/step - loss: 4.2197 - accuracy: 0.5233\n",
            "Epoch 21/150\n",
            "103/103 [==============================] - 727s 7s/step - loss: 4.1920 - accuracy: 0.5236\n",
            "Epoch 22/150\n",
            "103/103 [==============================] - 725s 7s/step - loss: 4.1730 - accuracy: 0.5241\n",
            "Epoch 23/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 4.1586 - accuracy: 0.5245\n",
            "Epoch 24/150\n",
            "103/103 [==============================] - 711s 7s/step - loss: 4.1441 - accuracy: 0.5249\n",
            "Epoch 25/150\n",
            "103/103 [==============================] - 719s 7s/step - loss: 4.1181 - accuracy: 0.5252\n",
            "Epoch 26/150\n",
            "103/103 [==============================] - 715s 7s/step - loss: 4.1006 - accuracy: 0.5257\n",
            "Epoch 27/150\n",
            "103/103 [==============================] - 713s 7s/step - loss: 4.0928 - accuracy: 0.5259\n",
            "Epoch 28/150\n",
            "103/103 [==============================] - 719s 7s/step - loss: 7.0289 - accuracy: 0.5268\n",
            "Epoch 29/150\n",
            "103/103 [==============================] - 717s 7s/step - loss: 4.1387 - accuracy: 0.5251\n",
            "Epoch 30/150\n",
            "103/103 [==============================] - 725s 7s/step - loss: 4.1210 - accuracy: 0.5254\n",
            "Epoch 31/150\n",
            "103/103 [==============================] - 718s 7s/step - loss: 4.1159 - accuracy: 0.5256\n",
            "Epoch 32/150\n",
            "103/103 [==============================] - 708s 7s/step - loss: 4.1114 - accuracy: 0.5262\n",
            "Epoch 33/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 4.1078 - accuracy: 0.5265\n",
            "Epoch 34/150\n",
            "103/103 [==============================] - 718s 7s/step - loss: 4.1044 - accuracy: 0.5266\n",
            "Epoch 35/150\n",
            "103/103 [==============================] - 730s 7s/step - loss: 4.0993 - accuracy: 0.5267\n",
            "Epoch 36/150\n",
            "103/103 [==============================] - 717s 7s/step - loss: 4.0935 - accuracy: 0.5268\n",
            "Epoch 37/150\n",
            "103/103 [==============================] - 717s 7s/step - loss: 4.0845 - accuracy: 0.5270\n",
            "Epoch 38/150\n",
            "103/103 [==============================] - 732s 7s/step - loss: 4.0786 - accuracy: 0.5271\n",
            "Epoch 39/150\n",
            "103/103 [==============================] - 717s 7s/step - loss: 4.0682 - accuracy: 0.5272\n",
            "Epoch 40/150\n",
            "103/103 [==============================] - 722s 7s/step - loss: 4.0620 - accuracy: 0.5273\n",
            "Epoch 41/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 4.0536 - accuracy: 0.5276\n",
            "Epoch 42/150\n",
            "103/103 [==============================] - 712s 7s/step - loss: 4.0439 - accuracy: 0.5278\n",
            "Epoch 43/150\n",
            "103/103 [==============================] - 714s 7s/step - loss: 4.0383 - accuracy: 0.5278\n",
            "Epoch 44/150\n",
            "103/103 [==============================] - 719s 7s/step - loss: 4.0282 - accuracy: 0.5279\n",
            "Epoch 45/150\n",
            "103/103 [==============================] - 1038s 10s/step - loss: 4.0234 - accuracy: 0.5281\n",
            "Epoch 46/150\n",
            "103/103 [==============================] - 704s 7s/step - loss: 4.0175 - accuracy: 0.5282\n",
            "Epoch 47/150\n",
            "103/103 [==============================] - 697s 7s/step - loss: 4.0106 - accuracy: 0.5285\n",
            "Epoch 48/150\n",
            "103/103 [==============================] - 699s 7s/step - loss: 4.0011 - accuracy: 0.5286\n",
            "Epoch 49/150\n",
            "103/103 [==============================] - 695s 7s/step - loss: 3.9950 - accuracy: 0.5288\n",
            "Epoch 50/150\n",
            "103/103 [==============================] - 702s 7s/step - loss: 3.9856 - accuracy: 0.5291\n",
            "Epoch 51/150\n",
            "103/103 [==============================] - 709s 7s/step - loss: 3.9762 - accuracy: 0.5299\n",
            "Epoch 52/150\n",
            "103/103 [==============================] - 699s 7s/step - loss: 3.9615 - accuracy: 0.5305\n",
            "Epoch 53/150\n",
            "103/103 [==============================] - 692s 7s/step - loss: 3.9509 - accuracy: 0.5309\n",
            "Epoch 54/150\n",
            "103/103 [==============================] - 709s 7s/step - loss: 3.9361 - accuracy: 0.5313\n",
            "Epoch 55/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 3.9248 - accuracy: 0.5316\n",
            "Epoch 56/150\n",
            "103/103 [==============================] - 904s 9s/step - loss: 3.9118 - accuracy: 0.5320\n",
            "Epoch 57/150\n",
            "103/103 [==============================] - 707s 7s/step - loss: 3.8925 - accuracy: 0.5329\n",
            "Epoch 58/150\n",
            "103/103 [==============================] - 709s 7s/step - loss: 3.8847 - accuracy: 0.5329\n",
            "Epoch 59/150\n",
            "103/103 [==============================] - 807s 8s/step - loss: 3.8747 - accuracy: 0.5333\n",
            "Epoch 60/150\n",
            "103/103 [==============================] - 997s 10s/step - loss: 3.8508 - accuracy: 0.5342\n",
            "Epoch 61/150\n",
            "103/103 [==============================] - 800s 8s/step - loss: 3.8441 - accuracy: 0.5345\n",
            "Epoch 62/150\n",
            "103/103 [==============================] - 907s 9s/step - loss: 3.8249 - accuracy: 0.5352\n",
            "Epoch 63/150\n",
            "103/103 [==============================] - 706s 7s/step - loss: 3.8168 - accuracy: 0.5354\n",
            "Epoch 64/150\n",
            "103/103 [==============================] - 709s 7s/step - loss: 3.8493 - accuracy: 0.5347\n",
            "Epoch 65/150\n",
            "103/103 [==============================] - 705s 7s/step - loss: 3.8433 - accuracy: 0.5346\n",
            "Epoch 66/150\n",
            "103/103 [==============================] - 703s 7s/step - loss: 3.8184 - accuracy: 0.5354\n",
            "Epoch 67/150\n",
            "103/103 [==============================] - 715s 7s/step - loss: 3.8038 - accuracy: 0.5360\n",
            "Epoch 68/150\n",
            "103/103 [==============================] - 713s 7s/step - loss: 3.8111 - accuracy: 0.5361\n",
            "Epoch 69/150\n",
            "103/103 [==============================] - 706s 7s/step - loss: 3.7986 - accuracy: 0.5366\n",
            "Epoch 70/150\n",
            "103/103 [==============================] - 716s 7s/step - loss: 3.7029 - accuracy: 0.5394\n",
            "Epoch 71/150\n",
            "103/103 [==============================] - 719s 7s/step - loss: 3.6963 - accuracy: 0.5394\n",
            "Epoch 72/150\n",
            "103/103 [==============================] - 712s 7s/step - loss: 3.7065 - accuracy: 0.5395\n",
            "Epoch 73/150\n",
            "103/103 [==============================] - 709s 7s/step - loss: 3.7590 - accuracy: 0.5377\n",
            "Epoch 74/150\n",
            "103/103 [==============================] - 711s 7s/step - loss: 3.7938 - accuracy: 0.5364\n",
            "Epoch 75/150\n",
            "103/103 [==============================] - 713s 7s/step - loss: 3.7105 - accuracy: 0.5384\n",
            "Epoch 76/150\n",
            "103/103 [==============================] - 715s 7s/step - loss: 3.2987 - accuracy: 0.5475\n",
            "Epoch 77/150\n",
            "103/103 [==============================] - 702s 7s/step - loss: 2.8051 - accuracy: 0.5715\n",
            "Epoch 78/150\n",
            "103/103 [==============================] - 708s 7s/step - loss: 2.4899 - accuracy: 0.5919\n",
            "Epoch 79/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 2.2930 - accuracy: 0.6138\n",
            "Epoch 80/150\n",
            "103/103 [==============================] - 711s 7s/step - loss: 2.1657 - accuracy: 0.6538\n",
            "Epoch 81/150\n",
            "103/103 [==============================] - 713s 7s/step - loss: 2.2014 - accuracy: 0.6661\n",
            "Epoch 82/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 2.3505 - accuracy: 0.6426\n",
            "Epoch 83/150\n",
            "103/103 [==============================] - 712s 7s/step - loss: 2.0163 - accuracy: 0.6968\n",
            "Epoch 84/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 2.0425 - accuracy: 0.7084\n",
            "Epoch 85/150\n",
            "103/103 [==============================] - 714s 7s/step - loss: 1.9335 - accuracy: 0.7292\n",
            "Epoch 86/150\n",
            "103/103 [==============================] - 714s 7s/step - loss: 1.8478 - accuracy: 0.7484\n",
            "Epoch 87/150\n",
            "103/103 [==============================] - 712s 7s/step - loss: 1.9291 - accuracy: 0.7337\n",
            "Epoch 88/150\n",
            "103/103 [==============================] - 714s 7s/step - loss: 1.9181 - accuracy: 0.7334\n",
            "Epoch 89/150\n",
            "103/103 [==============================] - 702s 7s/step - loss: 1.8736 - accuracy: 0.7439\n",
            "Epoch 90/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 1.9013 - accuracy: 0.7448\n",
            "Epoch 91/150\n",
            "103/103 [==============================] - 705s 7s/step - loss: 1.7853 - accuracy: 0.7610\n",
            "Epoch 92/150\n",
            "103/103 [==============================] - 707s 7s/step - loss: 1.7732 - accuracy: 0.7677\n",
            "Epoch 93/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 1.7185 - accuracy: 0.7760\n",
            "Epoch 94/150\n",
            "103/103 [==============================] - 707s 7s/step - loss: 1.6662 - accuracy: 0.7881\n",
            "Epoch 95/150\n",
            "103/103 [==============================] - 705s 7s/step - loss: 1.6612 - accuracy: 0.7899\n",
            "Epoch 96/150\n",
            "103/103 [==============================] - 715s 7s/step - loss: 1.7768 - accuracy: 0.7630\n",
            "Epoch 97/150\n",
            "103/103 [==============================] - 713s 7s/step - loss: 1.6734 - accuracy: 0.7827\n",
            "Epoch 98/150\n",
            "103/103 [==============================] - 708s 7s/step - loss: 1.6320 - accuracy: 0.7920\n",
            "Epoch 99/150\n",
            "103/103 [==============================] - 714s 7s/step - loss: 1.6351 - accuracy: 0.7920\n",
            "Epoch 100/150\n",
            "103/103 [==============================] - 714s 7s/step - loss: 1.6356 - accuracy: 0.7906\n",
            "Epoch 101/150\n",
            "103/103 [==============================] - 711s 7s/step - loss: 1.6110 - accuracy: 0.7951\n",
            "Epoch 102/150\n",
            "103/103 [==============================] - 703s 7s/step - loss: 1.5897 - accuracy: 0.7993\n",
            "Epoch 103/150\n",
            "103/103 [==============================] - 712s 7s/step - loss: 1.5974 - accuracy: 0.7974\n",
            "Epoch 104/150\n",
            "103/103 [==============================] - 718s 7s/step - loss: 1.5804 - accuracy: 0.8009\n",
            "Epoch 105/150\n",
            "103/103 [==============================] - 704s 7s/step - loss: 1.5546 - accuracy: 0.8053\n",
            "Epoch 106/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 1.5708 - accuracy: 0.8029\n",
            "Epoch 107/150\n",
            "103/103 [==============================] - 713s 7s/step - loss: 1.5798 - accuracy: 0.7968\n",
            "Epoch 108/150\n",
            "103/103 [==============================] - 709s 7s/step - loss: 1.8136 - accuracy: 0.7651\n",
            "Epoch 109/150\n",
            "103/103 [==============================] - 712s 7s/step - loss: 1.6955 - accuracy: 0.7780\n",
            "Epoch 110/150\n",
            "103/103 [==============================] - 707s 7s/step - loss: 1.5857 - accuracy: 0.7971\n",
            "Epoch 111/150\n",
            "103/103 [==============================] - 705s 7s/step - loss: 1.9505 - accuracy: 0.7339\n",
            "Epoch 112/150\n",
            "103/103 [==============================] - 705s 7s/step - loss: 1.7222 - accuracy: 0.7690\n",
            "Epoch 113/150\n",
            "103/103 [==============================] - 704s 7s/step - loss: 1.6248 - accuracy: 0.7868\n",
            "Epoch 114/150\n",
            "103/103 [==============================] - 704s 7s/step - loss: 1.6062 - accuracy: 0.7939\n",
            "Epoch 115/150\n",
            "103/103 [==============================] - 701s 7s/step - loss: 1.6135 - accuracy: 0.7929\n",
            "Epoch 116/150\n",
            "103/103 [==============================] - 702s 7s/step - loss: 1.6363 - accuracy: 0.7896\n",
            "Epoch 117/150\n",
            "103/103 [==============================] - 699s 7s/step - loss: 1.5561 - accuracy: 0.8029\n",
            "Epoch 118/150\n",
            "103/103 [==============================] - 704s 7s/step - loss: 1.5287 - accuracy: 0.8079\n",
            "Epoch 119/150\n",
            "103/103 [==============================] - 695s 7s/step - loss: 1.5587 - accuracy: 0.8020\n",
            "Epoch 120/150\n",
            "103/103 [==============================] - 703s 7s/step - loss: 1.5168 - accuracy: 0.8100\n",
            "Epoch 121/150\n",
            "103/103 [==============================] - 706s 7s/step - loss: 1.5225 - accuracy: 0.8098\n",
            "Epoch 122/150\n",
            "103/103 [==============================] - 699s 7s/step - loss: 1.5200 - accuracy: 0.8107\n",
            "Epoch 123/150\n",
            "103/103 [==============================] - 707s 7s/step - loss: 1.5454 - accuracy: 0.8065\n",
            "Epoch 124/150\n",
            "103/103 [==============================] - 707s 7s/step - loss: 1.4954 - accuracy: 0.8145\n",
            "Epoch 125/150\n",
            "103/103 [==============================] - 713s 7s/step - loss: 1.4983 - accuracy: 0.8135\n",
            "Epoch 126/150\n",
            "103/103 [==============================] - 707s 7s/step - loss: 1.5507 - accuracy: 0.8053\n",
            "Epoch 127/150\n",
            "103/103 [==============================] - 707s 7s/step - loss: 1.4823 - accuracy: 0.8160\n",
            "Epoch 128/150\n",
            "103/103 [==============================] - 708s 7s/step - loss: 1.5079 - accuracy: 0.8132\n",
            "Epoch 129/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 1.4991 - accuracy: 0.8109\n",
            "Epoch 130/150\n",
            "103/103 [==============================] - 709s 7s/step - loss: 1.4537 - accuracy: 0.8208\n",
            "Epoch 131/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 1.4631 - accuracy: 0.8190\n",
            "Epoch 132/150\n",
            "103/103 [==============================] - 700s 7s/step - loss: 1.4492 - accuracy: 0.8205\n",
            "Epoch 133/150\n",
            "103/103 [==============================] - 714s 7s/step - loss: 1.4485 - accuracy: 0.8198\n",
            "Epoch 134/150\n",
            "103/103 [==============================] - 707s 7s/step - loss: 1.6582 - accuracy: 0.8002\n",
            "Epoch 135/150\n",
            "103/103 [==============================] - 711s 7s/step - loss: 1.4763 - accuracy: 0.8160\n",
            "Epoch 136/150\n",
            "103/103 [==============================] - 703s 7s/step - loss: 1.4442 - accuracy: 0.8215\n",
            "Epoch 137/150\n",
            "103/103 [==============================] - 710s 7s/step - loss: 1.4476 - accuracy: 0.8217\n",
            "Epoch 138/150\n",
            "103/103 [==============================] - 708s 7s/step - loss: 1.4341 - accuracy: 0.8230\n",
            "Epoch 139/150\n",
            "103/103 [==============================] - 703s 7s/step - loss: 1.4463 - accuracy: 0.8207\n",
            "Epoch 140/150\n",
            "103/103 [==============================] - 703s 7s/step - loss: 1.4321 - accuracy: 0.8225\n",
            "Epoch 141/150\n",
            "103/103 [==============================] - 712s 7s/step - loss: 1.5404 - accuracy: 0.8015\n",
            "Epoch 142/150\n",
            " 94/103 [==========================>...] - ETA: 1:02 - loss: 1.4466 - accuracy: 0.8172"
          ]
        }
      ],
      "source": [
        "print(\"Train URL model...\")\n",
        "model = train_model(X_train_nlp, X_train_features, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjLUXysGATnz"
      },
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-LN1CUn8pP6",
        "outputId": "523a8845-f181-4456-e94b-3c51f3dfb501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluate URL model...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'model_eval' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8219a214b825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluate URL model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_nlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_eval' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"Evaluate URL model...\")\n",
        "model_eval(model, X_test_nlp, X_test_features, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYFqtVpaAbVt"
      },
      "source": [
        "# Conclusions\n",
        "Here we show an example of detecting malicious URLs with high Precision 0.995 and moderate Recall 0.55. This model is based just on the URL: processing the stactural of the URL and words in the URL, because many malicious URLs seem legitimate which means that it's impossible to detect them with our features, the recall is limited. We can improve the model by adding WHOIS (https://who.is/) and VirusTotal (https://www.virustotal.com/) infromation about the URL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F8AzWamCBH3"
      },
      "source": [
        "# References\n",
        "https://github.com/Antimalweb/URLNet\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "phishurl-appshield-combined-rnn-dnn-20220301.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
